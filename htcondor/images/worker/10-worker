DAEMON_LIST = MASTER, STARTD

# Reduced from the default of 5 mins
CCB_HEARTBEAT_INTERVAL = 120

# Run all jobs as user user
STARTER_ALLOW_RUNAS_OWNER = FALSE
SLOT1_USER = user
SLOT1_1_USER = user
SLOT1_2_USER = user
SLOT1_3_USER = user
SLOT1_4_USER = user
SLOT1_5_USER = user
SLOT1_6_USER = user
SLOT1_7_USER = user
SLOT1_8_USER = user
SLOT1_9_USER = user
SLOT1_10_USER = user
SLOT1_11_USER = user
SLOT1_12_USER = user
SLOT1_13_USER = user
SLOT1_14_USER = user
SLOT1_15_USER = user
SLOT1_16_USER = user
SLOT1_17_USER = user
SLOT1_18_USER = user
SLOT1_19_USER = user
SLOT1_20_USER = user
SLOT1_21_USER = user
SLOT1_22_USER = user
SLOT1_23_USER = user
SLOT1_24_USER = user
SLOT1_25_USER = user
SLOT1_26_USER = user
SLOT1_27_USER = user
SLOT1_28_USER = user
SLOT1_29_USER = user
SLOT1_30_USER = user
SLOT1_31_USER = user
SLOT1_32_USER = user
DEDICATED_EXECUTE_ACCOUNT_REGEXP = user

TRUST_UID_DOMAIN = True

# Shutdown startd if idle for too long
STARTD_NOCLAIM_SHUTDOWN = 1200

# Go back to Unclaimed/Idle after running a job which runs for > 1 second
#CLAIM_WORKLIFE = 1

# Shutdown startd if idle after running a job
#STARTD.DAEMON_SHUTDOWN = Activity == "Idle" && (CurrentTime - EnteredCurrentActivity > 1200) && (TotalTimeClaimedBusy =!= UNDEFINED && TotalTimeClaimedBusy > 0)

# Shutdown the master if the startd exits
# - MonitorSelfAge shouldn't be needed, but once I experienced the master
#   shutting down before the startd had actually started due to STARTD_StartTime
#   being zero
MASTER.DAEMON_SHUTDOWN = STARTD_StartTime =?= 0 && MonitorSelfAge > 1200

# We want only a single partitionable slot
NUM_SLOTS = 1
NUM_SLOTS_TYPE_1 = 1
SLOT_TYPE_1 = cpus=100%,mem=100%,auto
SLOT_TYPE_1_PARTITIONABLE = TRUE

# Advertise cores & machines
STARTD_ATTRS = $(STARTD_ATTRS), ProminenceCloud, ProminenceNodes, ProminenceCoresTotal, ProminenceDagJobId, ProminenceInfrastructureId, ProminenceLocation

# TCP keepalive fix for Azure
#TCP_KEEPALIVE_INTERVAL = 60

# Execute directory
EXECUTE = /home/prominence/condor

# Setup cgroups
#BASE_CGROUP = 
BASE_CGROUP = htcondor
CGROUP_MEMORY_LIMIT_POLICY = hard

# Needed to allow Singularity to work
DOCKER_DROP_ALL_CAPABILITIES = False

# Job prepare hook
CONTAINER_HOOK_PREPARE_JOB = /usr/local/bin/job-prepare-hook

# File transfer plugin
#FILETRANSFER_PLUGINS = /usr/local/libexec/condor_url_fetch

# Disable MOUNT_UNDER_SCRATCH (temporarily)
MOUNT_UNDER_SCRATCH = ""

# How often the collector should be updated
UPDATE_OFFSET = $RANDOM_INTEGER(0, 20)
UPDATE_INTERVAL = 200

# Quantize memory available
MEMORY = quantize( $(DETECTED_MEMORY), 1000 )
